# -*- coding: utf-8 -*-
"""PowerInfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13plgtCD-tn4ECIeT7k7yMKMq1uqLWL12
"""

!git clone https://github.com/SJTU-IPADS/PowerInfer.git

# Commented out IPython magic to ensure Python compatibility.
# %cd PowerInfer

!pwd

!pip install -r requirements.txt

!cmake -S . -B build -DLLAMA_CUBLAS=ON
!cmake --build build --config Release

## Download the model
!mkdir ReluLLaMA-13B-PowerInfer-GGUF

!wget -P ReluLLaMA-13B-PowerInfer-GGUF https://huggingface.co/PowerInfer/ReluLLaMA-13B-PowerInfer-GGUF/resolve/main/llama-13b-relu.powerinfer.gguf

## Performing Inferences
!./build/bin/main \
    -m ./ReluLLaMA-13B-PowerInfer-GGUF/llama-13b-relu.powerinfer.gguf \
    -n 128 \
    -t 8 \
    -p "AI is a technology"

## Inference execution with limited VRAM Usage
!./build/bin/main \
    -m ./ReluLLaMA-13B-PowerInfer-GGUF/llama-13b-relu.powerinfer.gguf \
    -n 128 \
    -t 8 \
    -p "AI is a technology" \
    --vram-budget 8



